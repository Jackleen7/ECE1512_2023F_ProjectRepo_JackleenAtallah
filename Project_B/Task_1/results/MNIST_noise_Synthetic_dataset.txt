eval_it_pool:  [0, 50, 100]
class c = 0: 5923 real images
class c = 1: 6742 real images
class c = 2: 5958 real images
class c = 3: 6131 real images
class c = 4: 5842 real images
class c = 5: 5421 real images
class c = 6: 5918 real images
class c = 7: 6265 real images
class c = 8: 5851 real images
class c = 9: 5949 real images
real images channel 0, mean = -0.0001, std = 1.0000
initialize synthetic data from random noise
[2023-11-30 17:08:18] training begins
-------------------------
Evaluation
model_train = ConvNet3, model_eval = ConvNet3, iteration = 0
[2023-11-30 17:08:21] Evaluate: epoch = 0020 train time = 1.1573 s train loss = 0.777777 train acc = 1.0000, test acc = 0.0438
----------------------------------------
-------------------------
Evaluation
model_train = ConvNet3, model_eval = VGG11, iteration = 0
[2023-11-30 17:08:23] Evaluate: epoch = 0020 train time = 0.7505 s train loss = 1.596593 train acc = 1.0000, test acc = 0.1334
----------------------------------------
[2023-11-30 17:08:32] iter = 0000, loss = 226.6828
[2023-11-30 17:08:41] iter = 0001, loss = 159.1430
[2023-11-30 17:08:50] iter = 0002, loss = 141.3729
[2023-11-30 17:09:00] iter = 0003, loss = 129.0077
[2023-11-30 17:09:09] iter = 0004, loss = 123.2755
[2023-11-30 17:09:18] iter = 0005, loss = 112.2738
[2023-11-30 17:09:27] iter = 0006, loss = 104.4674
[2023-11-30 17:09:36] iter = 0007, loss = 98.2136
[2023-11-30 17:09:45] iter = 0008, loss = 99.6569
[2023-11-30 17:09:54] iter = 0009, loss = 96.1068
[2023-11-30 17:10:03] iter = 0010, loss = 94.3588
[2023-11-30 17:10:12] iter = 0011, loss = 90.4352
[2023-11-30 17:10:21] iter = 0012, loss = 86.9300
[2023-11-30 17:10:31] iter = 0013, loss = 84.9231
[2023-11-30 17:10:40] iter = 0014, loss = 82.4728
[2023-11-30 17:10:49] iter = 0015, loss = 80.6253
[2023-11-30 17:10:59] iter = 0016, loss = 75.1821
[2023-11-30 17:11:08] iter = 0017, loss = 77.6761
[2023-11-30 17:11:18] iter = 0018, loss = 72.9605
[2023-11-30 17:11:27] iter = 0019, loss = 79.4138
[2023-11-30 17:11:36] iter = 0020, loss = 73.3105
[2023-11-30 17:11:45] iter = 0021, loss = 71.7913
[2023-11-30 17:11:54] iter = 0022, loss = 70.9266
[2023-11-30 17:12:03] iter = 0023, loss = 70.6448
[2023-11-30 17:12:12] iter = 0024, loss = 65.6775
[2023-11-30 17:12:21] iter = 0025, loss = 67.2861
[2023-11-30 17:12:30] iter = 0026, loss = 64.9107
[2023-11-30 17:12:39] iter = 0027, loss = 62.6107
[2023-11-30 17:12:49] iter = 0028, loss = 64.6944
[2023-11-30 17:12:58] iter = 0029, loss = 65.7206
[2023-11-30 17:13:08] iter = 0030, loss = 58.7880
[2023-11-30 17:13:17] iter = 0031, loss = 62.3380
[2023-11-30 17:13:26] iter = 0032, loss = 60.1297
[2023-11-30 17:13:35] iter = 0033, loss = 56.0941
[2023-11-30 17:13:44] iter = 0034, loss = 56.9578
[2023-11-30 17:13:53] iter = 0035, loss = 55.9466
[2023-11-30 17:14:02] iter = 0036, loss = 54.9851
[2023-11-30 17:14:11] iter = 0037, loss = 57.2979
[2023-11-30 17:14:20] iter = 0038, loss = 54.1810
[2023-11-30 17:14:29] iter = 0039, loss = 53.0193
[2023-11-30 17:14:39] iter = 0040, loss = 52.2580
[2023-11-30 17:14:48] iter = 0041, loss = 54.0013
[2023-11-30 17:14:57] iter = 0042, loss = 52.1323
[2023-11-30 17:15:06] iter = 0043, loss = 52.0172
[2023-11-30 17:15:16] iter = 0044, loss = 52.1603
[2023-11-30 17:15:25] iter = 0045, loss = 50.8607
[2023-11-30 17:15:34] iter = 0046, loss = 50.7226
[2023-11-30 17:15:43] iter = 0047, loss = 49.5269
[2023-11-30 17:15:52] iter = 0048, loss = 50.6687
[2023-11-30 17:16:01] iter = 0049, loss = 49.4861
-------------------------
Evaluation
model_train = ConvNet3, model_eval = ConvNet3, iteration = 50
[2023-11-30 17:16:03] Evaluate: epoch = 0020 train time = 0.2657 s train loss = 0.532872 train acc = 0.9800, test acc = 0.8825
----------------------------------------
-------------------------
Evaluation
model_train = ConvNet3, model_eval = VGG11, iteration = 50
[2023-11-30 17:16:05] Evaluate: epoch = 0020 train time = 0.6094 s train loss = 1.509628 train acc = 0.9200, test acc = 0.5942
----------------------------------------
[2023-11-30 17:16:14] iter = 0050, loss = 46.9629
[2023-11-30 17:16:23] iter = 0051, loss = 48.4276
[2023-11-30 17:16:33] iter = 0052, loss = 48.0133
[2023-11-30 17:16:42] iter = 0053, loss = 48.0775
[2023-11-30 17:16:52] iter = 0054, loss = 44.3224
[2023-11-30 17:17:01] iter = 0055, loss = 46.8849
[2023-11-30 17:17:10] iter = 0056, loss = 46.8414
[2023-11-30 17:17:19] iter = 0057, loss = 46.3004
[2023-11-30 17:17:29] iter = 0058, loss = 47.0917
[2023-11-30 17:17:38] iter = 0059, loss = 46.7289
[2023-11-30 17:17:47] iter = 0060, loss = 47.5274
[2023-11-30 17:17:56] iter = 0061, loss = 46.2954
[2023-11-30 17:18:05] iter = 0062, loss = 46.1391
[2023-11-30 17:18:14] iter = 0063, loss = 44.0161
[2023-11-30 17:18:23] iter = 0064, loss = 45.1454
[2023-11-30 17:18:32] iter = 0065, loss = 44.6103
[2023-11-30 17:18:41] iter = 0066, loss = 44.2107
[2023-11-30 17:18:51] iter = 0067, loss = 44.0925
[2023-11-30 17:19:00] iter = 0068, loss = 41.8994
[2023-11-30 17:19:09] iter = 0069, loss = 44.3394
[2023-11-30 17:19:19] iter = 0070, loss = 43.8904
[2023-11-30 17:19:28] iter = 0071, loss = 43.4339
[2023-11-30 17:19:37] iter = 0072, loss = 44.1764
[2023-11-30 17:19:46] iter = 0073, loss = 44.9558
[2023-11-30 17:19:55] iter = 0074, loss = 41.7579
[2023-11-30 17:20:03] iter = 0075, loss = 44.4497
[2023-11-30 17:20:12] iter = 0076, loss = 43.2159
[2023-11-30 17:20:22] iter = 0077, loss = 42.9857
[2023-11-30 17:20:31] iter = 0078, loss = 42.6094
[2023-11-30 17:20:40] iter = 0079, loss = 44.1930
[2023-11-30 17:20:49] iter = 0080, loss = 45.6379
[2023-11-30 17:20:58] iter = 0081, loss = 42.3760
[2023-11-30 17:21:08] iter = 0082, loss = 42.7824
[2023-11-30 17:21:17] iter = 0083, loss = 42.0185
[2023-11-30 17:21:26] iter = 0084, loss = 42.8772
[2023-11-30 17:21:35] iter = 0085, loss = 43.8723
[2023-11-30 17:21:44] iter = 0086, loss = 41.1688
[2023-11-30 17:21:53] iter = 0087, loss = 39.3461
[2023-11-30 17:22:02] iter = 0088, loss = 41.5813
[2023-11-30 17:22:11] iter = 0089, loss = 38.9058
[2023-11-30 17:22:20] iter = 0090, loss = 40.4060
[2023-11-30 17:22:30] iter = 0091, loss = 42.7957
[2023-11-30 17:22:39] iter = 0092, loss = 41.3144
[2023-11-30 17:22:48] iter = 0093, loss = 41.9090
[2023-11-30 17:22:58] iter = 0094, loss = 41.3857
[2023-11-30 17:23:07] iter = 0095, loss = 42.7247
[2023-11-30 17:23:16] iter = 0096, loss = 41.7676
[2023-11-30 17:23:25] iter = 0097, loss = 40.7042
[2023-11-30 17:23:34] iter = 0098, loss = 40.6827
[2023-11-30 17:23:43] iter = 0099, loss = 42.1077
-------------------------
Evaluation
model_train = ConvNet3, model_eval = ConvNet3, iteration = 100
[2023-11-30 17:23:45] Evaluate: epoch = 0020 train time = 0.2658 s train loss = 0.574308 train acc = 0.9900, test acc = 0.9020
----------------------------------------
-------------------------
Evaluation
model_train = ConvNet3, model_eval = VGG11, iteration = 100
[2023-11-30 17:23:48] Evaluate: epoch = 0020 train time = 0.5938 s train loss = 1.601575 train acc = 0.9300, test acc = 0.6399
----------------------------------------
[2023-11-30 17:23:57] iter = 0100, loss = 39.4269
